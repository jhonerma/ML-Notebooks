{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPU's: 12\n"
     ]
    }
   ],
   "source": [
    "# Show number of avlaible CPU threads\n",
    "# With mulithreading this number is twice the number of physical cores\n",
    "cpu_av = os.cpu_count()\n",
    "print(\"Number of available CPU's: {}\".format(cpu_av))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number CPUS that should be used per trial and dataloader\n",
    "# If set to 1 number of cucurrent training networking is equal to this number\n",
    "# In case of training with GPU this will be limited to number of models training simultaneously on GPU\n",
    "# So number of CPU threads for each trial can be increased \n",
    "cpus_per_trial = 1\n",
    "gpus_per_trial = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to data\n",
    "train_path = 'Data/data_train.npz'\n",
    "test_path = 'Data/data_test.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(train_path, allow_pickle=True)\n",
    "test_data = np.load(test_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_train = train_data['ClusterN']\n",
    "Cluster_train = train_data['Cluster']\n",
    "ClusterTiming_train = train_data['ClusterTiming']\n",
    "ClusterType_train = train_data['ClusterType']\n",
    "ClusterE_train = train_data['ClusterE']\n",
    "ClusterPt_train = train_data['ClusterPt']\n",
    "ClusterModuleNumber_train = train_data['ClusterModuleNumber']\n",
    "ClusterCol_train = train_data['ClusterCol']\n",
    "ClusterRow_train = train_data['ClusterRow']\n",
    "ClusterM02_train = train_data['ClusterM02']\n",
    "ClusterM20_train = train_data['ClusterM20']\n",
    "ClusterDistFromVert_train = train_data['ClusterDistFromVert']\n",
    "PartE_train = train_data['PartE']\n",
    "PartPt_train = train_data['PartPt']\n",
    "PartEta_train = train_data['PartEta']\n",
    "PartPhi_train = train_data['PartPhi']\n",
    "PartIsPrimary_train = train_data['PartIsPrimary']\n",
    "PartPID_train = train_data['PartPID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_test = test_data['ClusterN']\n",
    "Cluster_test = test_data['Cluster']\n",
    "ClusterTiming_test = test_data['ClusterTiming']\n",
    "ClusterType_test = test_data['ClusterType']\n",
    "ClusterE_test = test_data['ClusterE']\n",
    "ClusterPt_test = test_data['ClusterPt']\n",
    "ClusterModuleNumber_test = test_data['ClusterModuleNumber']\n",
    "ClusterCol_test = test_data['ClusterCol']\n",
    "ClusterRow_test = test_data['ClusterRow']\n",
    "ClusterM02_test = test_data['ClusterM02']\n",
    "ClusterM20_test = test_data['ClusterM20']\n",
    "ClusterDistFromVert_test = test_data['ClusterDistFromVert']\n",
    "PartE_test = test_data['PartE']\n",
    "PartPt_test = test_data['PartPt']\n",
    "PartEta_test = test_data['PartEta']\n",
    "PartPhi_test = test_data['PartPhi']\n",
    "PartIsPrimary_test = test_data['PartIsPrimary']\n",
    "PartPID_test = test_data['PartPID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary change for PID into three categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_pid(arr):\n",
    "    arr[np.nonzero((arr != 111) & (arr != 221))] = 0\n",
    "    arr[arr == 111] = 1\n",
    "    arr[arr == 221] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_pid(PartPID_test)\n",
    "change_pid(PartPID_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the arrays into [size, 1] for usage with ptorch\n",
    "\n",
    "For linear layers input is expected as [batch_size, num_features] so no need to reshape the existing arrays like Cluster\n",
    "\n",
    "reconstrcuted clusters later will have to have dim [batch_size, channel, height, width] as input for conv2d-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxClusN_train = np.max(ClusterN_train)\n",
    "maxClusN_test = np.max(ClusterN_test)\n",
    "maxClusN = np.max([maxClusN_test, maxClusN_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_train = ClusterN_train.reshape((ClusterN_train.size, 1))\n",
    "#Cluster_train = Cluster_train.reshape((ClusterE_train.size, maxClusN))\n",
    "ClusterType_train = ClusterType_train.reshape((ClusterType_train.size, 1))\n",
    "ClusterE_train = ClusterE_train.reshape((ClusterE_train.size, 1))\n",
    "ClusterPt_train = ClusterPt_train.reshape((ClusterPt_train.size, 1))\n",
    "#ClusterModuleNumber_train = ClusterModuleNumber_train.reshape((ClusterModuleNumber_train.size, maxClusN))\n",
    "#ClusterRow_train = ClusterRow_train.reshape((ClusterRow_train.size, maxClusN))\n",
    "#ClusterCol_train = ClusterCol_train.reshape((ClusterCol_train.size, maxClusN))\n",
    "ClusterM02_train = ClusterM02_train.reshape((ClusterM02_train.size, 1))\n",
    "ClusterM20_train = ClusterM20_train.reshape((ClusterM20_train.size, 1))\n",
    "ClusterDistFromVert_train = ClusterDistFromVert_train.reshape((ClusterDistFromVert_train.size, 1))\n",
    "PartE_train = PartE_train.reshape((PartE_train.size, 1))\n",
    "PartPt_train = PartPt_train.reshape((PartPt_train.size, 1))\n",
    "PartEta_train = PartEta_train.reshape((PartEta_train.size, 1))\n",
    "PartPhi_train = PartPhi_train.reshape((PartPhi_train.size, 1))\n",
    "PartIsPrimary_train = PartIsPrimary_train.reshape((PartIsPrimary_train.size, 1))\n",
    "PartPID_train = PartPID_train.reshape((PartPID_train.size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_test = ClusterN_test.reshape((ClusterN_test.size, 1))\n",
    "#Cluster_test = Cluster_test.reshape((ClusterE_test.size, maxClusN))\n",
    "ClusterType_test = ClusterType_test.reshape((ClusterType_test.size, 1))\n",
    "ClusterE_test = ClusterE_test.reshape((ClusterE_test.size, 1))\n",
    "ClusterPt_test = ClusterPt_test.reshape((ClusterPt_test.size, 1))\n",
    "#ClusterModuleNumber_test = ClusterModuleNumber_test.reshape((ClusterModuleNumber_test.size, maxClusN))\n",
    "#ClusterRow_test = ClusterRow_test.reshape((ClusterRow_test.size, maxClusN))\n",
    "#ClusterCol_test = ClusterCol_test.reshape((ClusterCol_test.size, maxClusN))\n",
    "ClusterM02_test = ClusterM02_test.reshape((ClusterM02_test.size, 1))\n",
    "ClusterM20_test = ClusterM20_test.reshape((ClusterM20_test.size, 1))\n",
    "ClusterDistFromVert_test = ClusterDistFromVert_test.reshape((ClusterDistFromVert_test.size, 1))\n",
    "PartE_test = PartE_test.reshape((PartE_test.size, 1))\n",
    "PartPt_test = PartPt_test.reshape((PartPt_test.size, 1))\n",
    "PartEta_test = PartEta_test.reshape((PartEta_test.size, 1))\n",
    "PartPhi_test = PartPhi_test.reshape((PartPhi_test.size, 1))\n",
    "PartIsPrimary_test = PartIsPrimary_test.reshape((PartIsPrimary_test.size, 1))\n",
    "PartPID_test = PartPID_test.reshape((PartPID_test.size, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load it to pytorch `tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_train = torch.as_tensor(ClusterN_train, dtype=torch.uint8)\n",
    "Cluster_train = torch.as_tensor(Cluster_train, dtype=torch.float32)\n",
    "ClusterTiming_train = torch.as_tensor(ClusterTiming_train, dtype=torch.float32)\n",
    "ClusterType_train = torch.as_tensor(ClusterType_train, dtype=torch.uint8)\n",
    "ClusterE_train = torch.as_tensor(ClusterE_train, dtype=torch.float32)\n",
    "ClusterPt_train = torch.as_tensor(ClusterPt_train, dtype=torch.float32)\n",
    "ClusterModuleNumber_train = torch.as_tensor(ClusterModuleNumber_train, dtype=torch.uint8)\n",
    "ClusterRow_train = torch.as_tensor(ClusterRow_train, dtype=torch.uint8)\n",
    "ClusterCol_train = torch.as_tensor(ClusterCol_train, dtype=torch.uint8)\n",
    "ClusterM02_train = torch.as_tensor(ClusterM02_train, dtype=torch.float32)\n",
    "ClusterM20_train = torch.as_tensor(ClusterM20_train, dtype=torch.float32)\n",
    "ClusterDistFromVert_train = torch.as_tensor(ClusterDistFromVert_train, dtype=torch.float32)\n",
    "PartE_train = torch.as_tensor(PartE_train, dtype=torch.float32)\n",
    "PartPt_train = torch.as_tensor(PartPt_train, dtype=torch.float32)\n",
    "PartEta_train = torch.as_tensor(PartEta_train, dtype=torch.float32)\n",
    "PartPhi_train = torch.as_tensor(PartPhi_train, dtype=torch.float32)\n",
    "PartIsPrimary_train = torch.as_tensor(PartIsPrimary_train, dtype=torch.bool)\n",
    "PartPID_train = torch.as_tensor(PartPID_train, dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterN_test = torch.as_tensor(ClusterN_test, dtype=torch.uint8)\n",
    "Cluster_test = torch.as_tensor(Cluster_test, dtype=torch.float32)\n",
    "ClusterTiming_test = torch.as_tensor(ClusterTiming_test, dtype=torch.float32)\n",
    "ClusterType_test = torch.as_tensor(ClusterType_test, dtype=torch.uint8)\n",
    "ClusterE_test = torch.as_tensor(ClusterE_test, dtype=torch.float32)\n",
    "ClusterPt_test = torch.as_tensor(ClusterPt_test, dtype=torch.float32)\n",
    "ClusterModuleNumber_test = torch.as_tensor(ClusterModuleNumber_test, dtype=torch.uint8)\n",
    "ClusterRow_test = torch.as_tensor(ClusterRow_test, dtype=torch.uint8)\n",
    "ClusterCol_test = torch.as_tensor(ClusterCol_test, dtype=torch.uint8)\n",
    "ClusterM02_test = torch.as_tensor(ClusterM02_test, dtype=torch.float32)\n",
    "ClusterM20_test = torch.as_tensor(ClusterM20_test, dtype=torch.float32)\n",
    "ClusterDistFromVert_test = torch.as_tensor(ClusterDistFromVert_test, dtype=torch.float32)\n",
    "PartE_test = torch.as_tensor(PartE_test, dtype=torch.float32)\n",
    "PartPt_test = torch.as_tensor(PartPt_test, dtype=torch.float32)\n",
    "PartEta_test = torch.as_tensor(PartEta_test, dtype=torch.float32)\n",
    "PartPhi_test = torch.as_tensor(PartPhi_test, dtype=torch.float32)\n",
    "PartIsPrimary_test = torch.as_tensor(PartIsPrimary_test, dtype=torch.bool)\n",
    "PartPID_test = torch.as_tensor(PartPID_test, dtype=torch.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions for DataSet and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_train():\n",
    "    dataset_train = utils.TensorDataset( ClusterN_train, Cluster_train, ClusterTiming_train, ClusterType_train\n",
    "                                    , ClusterE_train, ClusterPt_train, ClusterModuleNumber_train\n",
    "                                    , ClusterRow_train, ClusterCol_train, ClusterM02_train, ClusterM20_train\n",
    "                                    , ClusterDistFromVert_train, PartE_train, PartPt_train\n",
    "                                    , PartEta_train, PartPhi_train, PartIsPrimary_train, PartPID_train )\n",
    "    \n",
    "    return dataset_train\n",
    "\n",
    "def load_data_test():\n",
    "    dataset_test = utils.TensorDataset( ClusterN_test, Cluster_test, ClusterTiming_test, ClusterType_test\n",
    "                                   , ClusterE_test, ClusterPt_test, ClusterModuleNumber_test\n",
    "                                   , ClusterRow_test, ClusterCol_test, ClusterM02_test, ClusterM20_test\n",
    "                                   , ClusterDistFromVert_test, PartE_test, PartPt_test\n",
    "                                    , PartEta_test, PartPhi_test, PartIsPrimary_test, PartPID_test )\n",
    "    \n",
    "    return dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(train_ds, val_ds, bs):\n",
    "    return (\n",
    "        utils.DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=cpus_per_trial),\n",
    "        utils.DataLoader(val_ds, batch_size=bs * 2, shuffle=True, num_workers=cpus_per_trial),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/abs/1610.04490\n",
    "INSTANCE_NOISE = False\n",
    "\n",
    "def add_instance_noise(data, std=0.01):\n",
    "    return data + torch.distributions.Normal(0, std).sample(data.shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, l1=100, l2=50, l3=25):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size=3, padding=2)\n",
    "        self.conv2 = nn.Conv2d(10,10, kernel_size=3,  padding=2)\n",
    "        self.conv3 = nn.Conv2d(10,10, kernel_size=3, padding=0)\n",
    "        self.conv4 = nn.Conv2d(10,5, kernel_size=1, padding=0)\n",
    "        self.conv5 = nn.Conv2d(5,3, kernel_size=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense_nn = nn.Sequential(\n",
    "            nn.Linear(4005, l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1, l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1, l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l2, l3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l3,3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, cluster, clusNumXYEPt):\n",
    "        cluster = F.relu(self.conv1(cluster))\n",
    "        cluster = F.relu(self.conv2(cluster))\n",
    "        cluster = F.relu(self.conv3(cluster))\n",
    "        cluster = F.relu(self.conv3(cluster))\n",
    "        x = self.flatten(cluster)\n",
    "        x = torch.cat([x, clusNumXYEPt], dim=1)\n",
    "        logits = self.dense_nn(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for cluster reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_cluster(ncell, modnum, row, col, data, arrsize=20):\n",
    "    if not torch.all( modnum[0] == modnum[:ncell]):\n",
    "        ModNumDif = modnum - torch.min(modnum[:ncell])\n",
    "        mask = torch.where(ModNumDif == 1)\n",
    "        col[mask] += 48\n",
    "        mask = torch.where(ModNumDif == 2)\n",
    "        row[mask] += 24\n",
    "        mask = torch.where(ModNumDif == 3)\n",
    "        row[mask] += 24\n",
    "        col[mask] += 48\n",
    "\n",
    "    arr = torch.zeros((arrsize,arrsize), dtype=torch.float32)\n",
    "  \n",
    "    col_min = torch.min(col[:ncell])\n",
    "    row_min = torch.min(row[:ncell])\n",
    "    width = torch.max(col[:ncell]) - col_min\n",
    "    height = torch.max(row[:ncell]) - row_min\n",
    "    offset_h = ((arrsize-height)/2).int()\n",
    "    offset_w = ((arrsize-width)/2).int()\n",
    "    \n",
    "    for i in range(ncell):\n",
    "        arr[ row[i] - row_min + offset_h, col[i] - col_min + offset_w ] = data[i]\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement train and validation loop\n",
    "[0: 'ClusterN', 1:'Cluster', 2:'ClusterTiming', 3:'ClusterType', 4:'ClusterE', 5:'ClusterPt', 6:'ClusterModuleNumber', 7:'ClusterRow', 8:'ClusterCol', 9:'ClusterM02', 10:'ClusterM20', 11:'ClusterDistFromVert', 12:'PartE', 13:'PartPt', 14:'PartEta', 15:'PartPhi', 16:'PartIsPrimary', 17:'PartPID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epoch, dataloader, model, loss_fn, optimizer, device=\"cpu\"):\n",
    "    size = len(dataloader.dataset)\n",
    "    running_loss = 0.0\n",
    "    epoch_steps = 0\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        ClN, Cl, ClE, ClPt, ClModNum, ClRow, ClCol, ClM02, ClM20, ClDist, PartPID = data[0], data[1],\\\n",
    "        data[4], data[5], data[6], \\\n",
    "        data[7], data[8], data[9], data[10], \\\n",
    "        data[11], data[17]\n",
    "        \n",
    "        # reconstruct clusters from data\n",
    "        clusters_e = []\n",
    "\n",
    "        for i in range(ClN.shape[0]):\n",
    "            cluster_e = reconstruct_cluster(ClN[i], ClModNum[i], ClRow[i], ClCol[i], Cl[i])\n",
    "            clusters_e.append(cluster_e)\n",
    "        \n",
    "        clusters_e = torch.stack(clusters_e)\n",
    "        clusters_e = clusters_e.view(-1, 1, 20,20)\n",
    "        if INSTANCE_NOISE:\n",
    "            clusters_e = add_instance_noise(clusters_e)\n",
    "        clusters_e.to(device)\n",
    "        \n",
    "        ClusterProperties = torch.cat([ClE, ClPt, ClM02, ClM20, ClDist], dim=1)\n",
    "        ClusterProperties.to(device)\n",
    "               \n",
    "        # zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # prediction and loss\n",
    "        pred = model(clusters_e, ClusterProperties)\n",
    "        loss = loss_fn(pred, PartPID[:,0].long())\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        epoch_steps += 1\n",
    "        \n",
    "        if batch % 10 == 9:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, batch + 1,\n",
    "                                            running_loss / epoch_steps))\n",
    "            running_loss = 0.0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(epoch, dataloader, model, loss_fn, optimizer, device=\"cpu\"):\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, data in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            ClN, Cl, ClE, ClPt, ClModNum, ClRow, ClCol, ClM02, ClM20, ClDist, PartPID = data[0], data[1],\\\n",
    "            data[4], data[5], data[6], \\\n",
    "            data[7], data[8], data[9], data[10], \\\n",
    "            data[11], data[17]\n",
    "        \n",
    "            # reconstruct clusters from data\n",
    "            clusters_e = []\n",
    "\n",
    "            for i in range(ClN.shape[0]):\n",
    "                cluster_e = reconstruct_cluster(ClN[i], ClModNum[i], ClRow[i], ClCol[i], Cl[i])\n",
    "                clusters_e.append(cluster_e)\n",
    "        \n",
    "            clusters_e = torch.stack(clusters_e)\n",
    "            clusters_e = clusters_e.view(-1, 1, 20,20)\n",
    "            if INSTANCE_NOISE:\n",
    "                clusters_e = add_instance_noise(clusters_e)\n",
    "            clusters_e.to(device)\n",
    "        \n",
    "            ClusterProperties = torch.cat([ClE, ClPt, ClM02, ClM20, ClDist], dim=1)\n",
    "            ClusterProperties.to(device)\n",
    "            \n",
    "            pred = model(clusters_e, ClusterProperties)\n",
    "            correct += (pred.argmax(1) == PartPID[:,0]).type(torch.float).sum().item()\n",
    "\n",
    "            loss = loss_fn(pred, PartPID[:,0].long())#.item()\n",
    "            val_loss += loss.cpu().numpy()\n",
    "            val_steps += 1\n",
    "    \n",
    "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "        torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "        \n",
    "    tune.report(loss=(val_loss / val_steps), accuracy= correct / size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, checkpoint_dir=None):\n",
    "    \n",
    "    # load model\n",
    "    model = CNN(config[\"l1\"],config[\"l2\"],config[\"l3\"])\n",
    "    \n",
    "    # check for avlaible resource and initialize device\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "    # send model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # initialise loss function and opptimizer\n",
    "    loss_fn = F.cross_entropy\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=config[\"lr\"])\n",
    "    \n",
    "    # check whether checkpoint is available\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "    # load dataset\n",
    "    dataset_train = load_data_train()\n",
    "    \n",
    "    # split trainset in train and validation subsets\n",
    "    test_abs = int(len(dataset_train) * 0.8)\n",
    "    subset_train, subset_val = utils.random_split(\n",
    "        dataset_train, [test_abs, len(dataset_train) - test_abs])\n",
    "    \n",
    "    # get dataloaders \n",
    "    dataloader_train, dataloader_val = get_dataloader(subset_train, subset_val, int(config[\"batch_size\"]))\n",
    "                                                      \n",
    "    for epoch in range(100):\n",
    "        train_loop(epoch, dataloader_train, model, loss_fn, optimizer, device=device)\n",
    "        val_loop(epoch, dataloader_train, model, loss_fn, optimizer, device=device)                                              \n",
    "    \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement method for accuracy testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, device=\"cpu\"):\n",
    "    \n",
    "    dataset_test = load_data_test()\n",
    "    \n",
    "    dataloader_test = utils.DataLoader(\n",
    "        dataset_test, batch_size=4, shuffle=False, num_workers=2)\n",
    "    \n",
    "    correct = 0\n",
    "    total = len(dataloader_test.dataset)\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader_test:\n",
    "            ClN, Cl, ClE, ClPt, ClModNum, ClRow, ClCol, ClM02, ClM20, ClDist, PartPID = data[0], data[1],\\\n",
    "            data[4], data[5], data[6], \\\n",
    "            data[7], data[8], data[9], data[10], \\\n",
    "            data[11], data[17]\n",
    "        \n",
    "            # reconstruct clusters from data\n",
    "            clusters_e = []\n",
    "\n",
    "            for i in range(ClN.shape[0]):\n",
    "                cluster_e = reconstruct_cluster(ClN[i], ClModNum[i], ClRow[i], ClCol[i], Cl[i])\n",
    "                clusters_e.append(cluster_e)\n",
    "        \n",
    "            clusters_e = torch.stack(clusters_e)\n",
    "            clusters_e = clusters_e.view(-1, 1, 20,20)\n",
    "            if INSTANCE_NOISE:\n",
    "                clusters_e = add_instance_noise(clusters_e)\n",
    "            clusters_e.to(device)\n",
    "        \n",
    "            ClusterProperties = torch.cat([ClE, ClPt, ClM02, ClM20, ClDist], dim=1)\n",
    "            ClusterProperties.to(device)\n",
    "            \n",
    "            pred = model(clusters_e, ClusterProperties)\n",
    "            correct += (pred.argmax(1) == PartPID[:,0]).type(torch.float).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup all Ray Tune functionality and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=1):\n",
    "    \n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 10)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 10)),\n",
    "        \"l3\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 10)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16, 32, 64])\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"l1\", \"l2\", \"l3\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    \n",
    "    result = tune.run(\n",
    "        partial(train_model),\n",
    "        resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        local_dir = \"./Ray_Results\",\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "    \n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n",
    "    \n",
    "    best_trained_model = CNN(best_trial.config[\"l1\"], best_trial.config[\"l2\"], best_trial.config[\"l3\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "    \n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "    \n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 14:09:26,859\tERROR services.py:1272 -- Failed to start the dashboard: Failed to start the dashboard, return code 0. The last 10 lines of /tmp/ray/session_2021-09-15_14-09-25_856419_199151/logs/dashboard.log:\n",
      "  File \"/home/jhonerma/anaconda3/envs/cnn-env/lib/python3.9/site-packages/ray/new_dashboard/dashboard.py\", line 207, in <module>\n",
      "    dashboard = Dashboard(\n",
      "  File \"/home/jhonerma/anaconda3/envs/cnn-env/lib/python3.9/site-packages/ray/new_dashboard/dashboard.py\", line 98, in __init__\n",
      "    raise ex\n",
      "  File \"/home/jhonerma/anaconda3/envs/cnn-env/lib/python3.9/site-packages/ray/new_dashboard/dashboard.py\", line 89, in __init__\n",
      "    build_dir = setup_static_dir()\n",
      "  File \"/home/jhonerma/anaconda3/envs/cnn-env/lib/python3.9/site-packages/ray/new_dashboard/dashboard.py\", line 42, in setup_static_dir\n",
      "    raise FrontendNotFoundError(\n",
      "FrontendNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/new_dashboard/client && npm install && npm ci && npm run build): '/home/jhonerma/anaconda3/envs/cnn-env/lib/python3.9/site-packages/ray/new_dashboard/client/build'\n",
      "2021-09-15 14:09:27,765\tWARNING experiment.py:295 -- No name detected on trainable. Using DEFAULT.\n",
      "2021-09-15 14:09:27,766\tINFO registry.py:66 -- Detected unknown callable for trainable. Converting to class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 6.1/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 1.0/12 CPUs, 0/0 GPUs, 0.0/6.26 GiB heap, 0.0/3.13 GiB objects\n",
      "Result logdir: /home/jhonerma/ML-Notebooks/CNN/Ray_Results/DEFAULT_2021-09-15_14-09-27\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------+----------+-------+------+------+------+-------------+--------------+\n",
      "| Trial name          | status   | loc   |   l1 |   l2 |   l3 |          lr |   batch_size |\n",
      "|---------------------+----------+-------+------+------+------+-------------+--------------|\n",
      "| DEFAULT_c643d_00000 | RUNNING  |       |  128 |    8 |   32 | 0.00054301  |            4 |\n",
      "| DEFAULT_c643d_00001 | PENDING  |       |   16 |    4 |  256 | 0.000347418 |            4 |\n",
      "| DEFAULT_c643d_00002 | PENDING  |       |  256 |   32 |  512 | 0.00165889  |           32 |\n",
      "| DEFAULT_c643d_00003 | PENDING  |       |  256 |  128 |   32 | 0.000380206 |            8 |\n",
      "| DEFAULT_c643d_00004 | PENDING  |       |   64 |  512 |    4 | 0.000179362 |           32 |\n",
      "| DEFAULT_c643d_00005 | PENDING  |       |   64 |  512 |    4 | 0.00023156  |            8 |\n",
      "| DEFAULT_c643d_00006 | PENDING  |       |    4 |   16 |   32 | 0.00704958  |           64 |\n",
      "| DEFAULT_c643d_00007 | PENDING  |       |  512 |   32 |  128 | 0.0014271   |            4 |\n",
      "| DEFAULT_c643d_00008 | PENDING  |       |  128 |    8 |    8 | 0.00439477  |            4 |\n",
      "| DEFAULT_c643d_00009 | PENDING  |       |    4 |   64 |   64 | 0.0772433   |            4 |\n",
      "+---------------------+----------+-------+------+------+------+-------------+--------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=199267)\u001b[0m [1,    10] loss: 1.102\n",
      "\u001b[2m\u001b[36m(pid=199271)\u001b[0m [1,    10] loss: 1.106\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [1,    10] loss: 2.314\n",
      "\u001b[2m\u001b[36m(pid=199270)\u001b[0m [1,    10] loss: 1.102\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [1,    10] loss: 1.195\n",
      "Result for DEFAULT_c643d_00006:\n",
      "  accuracy: 0.22448979591836735\n",
      "  date: 2021-09-15_14-09-29\n",
      "  done: false\n",
      "  experiment_id: 1d106c223a684fbfb77a0bcf133db0eb\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1041776736577351\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199272\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.615189790725708\n",
      "  time_this_iter_s: 0.615189790725708\n",
      "  time_total_s: 0.615189790725708\n",
      "  timestamp: 1631707769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00006\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199271)\u001b[0m [1,    20] loss: 0.549\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [1,    10] loss: 0.858\n",
      "Result for DEFAULT_c643d_00004:\n",
      "  accuracy: 0.23809523809523808\n",
      "  date: 2021-09-15_14-09-29\n",
      "  done: true\n",
      "  experiment_id: 792ec0a940594c03b33681f0f5bd7472\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.1575098037719727\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199263\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7272310256958008\n",
      "  time_this_iter_s: 0.7272310256958008\n",
      "  time_total_s: 0.7272310256958008\n",
      "  timestamp: 1631707769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00004\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [1,    20] loss: 0.384\n",
      "Result for DEFAULT_c643d_00002:\n",
      "  accuracy: 0.23129251700680273\n",
      "  date: 2021-09-15_14-09-29\n",
      "  done: false\n",
      "  experiment_id: 1473e196d9d344f0abb7214cc81d0756\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.09861216545105\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199266\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.8878724575042725\n",
      "  time_this_iter_s: 0.8878724575042725\n",
      "  time_total_s: 0.8878724575042725\n",
      "  timestamp: 1631707769\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00002\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199267)\u001b[0m [1,    20] loss: 0.549\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [1,    20] loss: 0.504\n",
      "\u001b[2m\u001b[36m(pid=199271)\u001b[0m [1,    30] loss: 0.366\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [1,    30] loss: 0.349\n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [1,    10] loss: 1.135\n",
      "Result for DEFAULT_c643d_00005:\n",
      "  accuracy: 0.19047619047619047\n",
      "  date: 2021-09-15_14-09-30\n",
      "  done: false\n",
      "  experiment_id: fcf7bde66e654766b13d32325dda3b0e\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199270\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.1127467155456543\n",
      "  time_this_iter_s: 1.1127467155456543\n",
      "  time_total_s: 1.1127467155456543\n",
      "  timestamp: 1631707770\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00005\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [1,    30] loss: 0.338\n",
      "\u001b[2m\u001b[36m(pid=199267)\u001b[0m [1,    30] loss: 0.366\n",
      "\u001b[2m\u001b[36m(pid=199270)\u001b[0m [2,    10] loss: 1.099\n",
      "Result for DEFAULT_c643d_00002:\n",
      "  accuracy: 0.23129251700680273\n",
      "  date: 2021-09-15_14-09-30\n",
      "  done: true\n",
      "  experiment_id: 1473e196d9d344f0abb7214cc81d0756\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 1.09861216545105\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199266\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.6822969913482666\n",
      "  time_this_iter_s: 0.7944245338439941\n",
      "  time_total_s: 1.6822969913482666\n",
      "  timestamp: 1631707770\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c643d_00002\n",
      "  \n",
      "Result for DEFAULT_c643d_00003:\n",
      "  accuracy: 0.7278911564625851\n",
      "  date: 2021-09-15_14-09-30\n",
      "  done: false\n",
      "  experiment_id: d06bbe2892a44502a1dd0c9ae6948c90\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7945723392461476\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199273\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.744063138961792\n",
      "  time_this_iter_s: 1.744063138961792\n",
      "  time_total_s: 1.744063138961792\n",
      "  timestamp: 1631707770\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00003\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [1,    20] loss: 0.549\n",
      "Result for DEFAULT_c643d_00009:\n",
      "  accuracy: 0.6870748299319728\n",
      "  date: 2021-09-15_14-09-30\n",
      "  done: false\n",
      "  experiment_id: 83f948441e7c4824a8903a62db413e13\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.8834863047342043\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.7372071743011475\n",
      "  time_this_iter_s: 1.7372071743011475\n",
      "  time_total_s: 1.7372071743011475\n",
      "  timestamp: 1631707770\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00009\n",
      "  \n",
      "Result for DEFAULT_c643d_00001:\n",
      "  accuracy: 0.22448979591836735\n",
      "  date: 2021-09-15_14-09-30\n",
      "  done: true\n",
      "  experiment_id: 6c8e022969ee4e209c05cbb6f4bd3329\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199271\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.9018702507019043\n",
      "  time_this_iter_s: 1.9018702507019043\n",
      "  time_total_s: 1.9018702507019043\n",
      "  timestamp: 1631707770\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00001\n",
      "  \n",
      "Result for DEFAULT_c643d_00008:\n",
      "  accuracy: 0.7074829931972789\n",
      "  date: 2021-09-15_14-09-31\n",
      "  done: false\n",
      "  experiment_id: 211e3aa6d104480f813511e28f6bf05e\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.8731698377712352\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199265\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.127612352371216\n",
      "  time_this_iter_s: 2.127612352371216\n",
      "  time_total_s: 2.127612352371216\n",
      "  timestamp: 1631707771\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00008\n",
      "  \n",
      "Result for DEFAULT_c643d_00000:\n",
      "  accuracy: 0.2108843537414966\n",
      "  date: 2021-09-15_14-09-31\n",
      "  done: true\n",
      "  experiment_id: a89f24b8fbf345578ed2acdf7c70fe66\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199267\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.179264783859253\n",
      "  time_this_iter_s: 2.179264783859253\n",
      "  time_total_s: 2.179264783859253\n",
      "  timestamp: 1631707771\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00000\n",
      "  \n",
      "Result for DEFAULT_c643d_00005:\n",
      "  accuracy: 0.19047619047619047\n",
      "  date: 2021-09-15_14-09-31\n",
      "  done: true\n",
      "  experiment_id: fcf7bde66e654766b13d32325dda3b0e\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199270\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.1359310150146484\n",
      "  time_this_iter_s: 1.0231842994689941\n",
      "  time_total_s: 2.1359310150146484\n",
      "  timestamp: 1631707771\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c643d_00005\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [2,    10] loss: 0.903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [2,    10] loss: 0.793\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [2,    20] loss: 0.429\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [2,    10] loss: 0.782\n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [1,    30] loss: 0.366\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [2,    30] loss: 0.273\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [2,    20] loss: 0.343\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [2,    30] loss: 0.300\n",
      "Result for DEFAULT_c643d_00007:\n",
      "  accuracy: 0.21768707482993196\n",
      "  date: 2021-09-15_14-09-32\n",
      "  done: false\n",
      "  experiment_id: 777e5acb4d214720bb933ef53577927f\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199269\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.065727949142456\n",
      "  time_this_iter_s: 3.065727949142456\n",
      "  time_total_s: 3.065727949142456\n",
      "  timestamp: 1631707772\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c643d_00007\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [3,    10] loss: 0.746\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [3,    10] loss: 0.760\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [3,    20] loss: 0.474\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [3,    30] loss: 0.312\n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [2,    10] loss: 1.099\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [3,    10] loss: 0.843\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [3,    20] loss: 0.372\n",
      "== Status ==\n",
      "Memory usage on this node: 6.6/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 8.000: -1.0986120700836182 | Iter 4.000: -1.0986120700836182 | Iter 2.000: -0.9726589442910375 | Iter 1.000: -1.0986123085021973\n",
      "Resources requested: 5.0/12 CPUs, 0/0 GPUs, 0.0/6.26 GiB heap, 0.0/3.13 GiB objects\n",
      "Result logdir: /home/jhonerma/ML-Notebooks/CNN/Ray_Results/DEFAULT_2021-09-15_14-09-27\n",
      "Number of trials: 10/10 (5 RUNNING, 5 TERMINATED)\n",
      "+---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "| Trial name          | status     | loc                |   l1 |   l2 |   l3 |          lr |   batch_size |     loss |   accuracy |   training_iteration |\n",
      "|---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------|\n",
      "| DEFAULT_c643d_00003 | RUNNING    | 10.67.95.37:199273 |  256 |  128 |   32 | 0.000380206 |            8 | 0.779884 |   0.727891 |                    3 |\n",
      "| DEFAULT_c643d_00006 | RUNNING    | 10.67.95.37:199272 |    4 |   16 |   32 | 0.00704958  |           64 | 1.09861  |   0.22449  |                    8 |\n",
      "| DEFAULT_c643d_00007 | RUNNING    | 10.67.95.37:199269 |  512 |   32 |  128 | 0.0014271   |            4 | 1.09861  |   0.217687 |                    1 |\n",
      "| DEFAULT_c643d_00008 | RUNNING    | 10.67.95.37:199265 |  128 |    8 |    8 | 0.00439477  |            4 | 0.843755 |   0.707483 |                    2 |\n",
      "| DEFAULT_c643d_00009 | RUNNING    | 10.67.95.37:199268 |    4 |   64 |   64 | 0.0772433   |            4 | 0.847225 |   0.687075 |                    3 |\n",
      "| DEFAULT_c643d_00000 | TERMINATED |                    |  128 |    8 |   32 | 0.00054301  |            4 | 1.09861  |   0.210884 |                    1 |\n",
      "| DEFAULT_c643d_00001 | TERMINATED |                    |   16 |    4 |  256 | 0.000347418 |            4 | 1.09861  |   0.22449  |                    1 |\n",
      "| DEFAULT_c643d_00002 | TERMINATED |                    |  256 |   32 |  512 | 0.00165889  |           32 | 1.09861  |   0.231293 |                    2 |\n",
      "| DEFAULT_c643d_00004 | TERMINATED |                    |   64 |  512 |    4 | 0.000179362 |           32 | 1.15751  |   0.238095 |                    1 |\n",
      "| DEFAULT_c643d_00005 | TERMINATED |                    |   64 |  512 |    4 | 0.00023156  |            8 | 1.09861  |   0.190476 |                    2 |\n",
      "+---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [3,    30] loss: 0.323\n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [2,    20] loss: 0.549\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [4,    10] loss: 0.894\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [4,    10] loss: 0.742\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [4,    20] loss: 0.411\n",
      "Result for DEFAULT_c643d_00006:\n",
      "  accuracy: 0.22448979591836735\n",
      "  date: 2021-09-15_14-09-33\n",
      "  done: true\n",
      "  experiment_id: 1d106c223a684fbfb77a0bcf133db0eb\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 10\n",
      "  loss: 1.0986120700836182\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199272\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.640075922012329\n",
      "  time_this_iter_s: 0.419874906539917\n",
      "  time_total_s: 4.640075922012329\n",
      "  timestamp: 1631707773\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c643d_00006\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [4,    30] loss: 0.299\n",
      "\u001b[2m\u001b[36m(pid=199269)\u001b[0m [2,    30] loss: 0.366\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [4,    10] loss: 0.822\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [4,    20] loss: 0.422\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [5,    10] loss: 0.937\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [5,    10] loss: 0.968\n",
      "Result for DEFAULT_c643d_00007:\n",
      "  accuracy: 0.21768707482993196\n",
      "  date: 2021-09-15_14-09-34\n",
      "  done: true\n",
      "  experiment_id: 777e5acb4d214720bb933ef53577927f\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 1.0986123085021973\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199269\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.399447679519653\n",
      "  time_this_iter_s: 2.3337197303771973\n",
      "  time_total_s: 5.399447679519653\n",
      "  timestamp: 1631707774\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: c643d_00007\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [5,    20] loss: 0.399\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [4,    30] loss: 0.262\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [5,    30] loss: 0.262\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [6,    10] loss: 0.972\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [6,    10] loss: 0.946\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [5,    10] loss: 0.789\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [6,    20] loss: 0.434\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [5,    20] loss: 0.400\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [6,    30] loss: 0.271\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [5,    30] loss: 0.235\n",
      "Result for DEFAULT_c643d_00003:\n",
      "  accuracy: 0.7278911564625851\n",
      "  date: 2021-09-15_14-09-35\n",
      "  done: false\n",
      "  experiment_id: d06bbe2892a44502a1dd0c9ae6948c90\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.7728158439460554\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199273\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.760653257369995\n",
      "  time_this_iter_s: 0.8466060161590576\n",
      "  time_total_s: 6.760653257369995\n",
      "  timestamp: 1631707775\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: c643d_00003\n",
      "  \n",
      "Result for DEFAULT_c643d_00009:\n",
      "  accuracy: 0.6870748299319728\n",
      "  date: 2021-09-15_14-09-36\n",
      "  done: false\n",
      "  experiment_id: 83f948441e7c4824a8903a62db413e13\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 6\n",
      "  loss: 0.8388478675404111\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.841484546661377\n",
      "  time_this_iter_s: 0.8659656047821045\n",
      "  time_total_s: 6.841484546661377\n",
      "  timestamp: 1631707776\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 6\n",
      "  trial_id: c643d_00009\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [7,    10] loss: 0.752\n",
      "Result for DEFAULT_c643d_00008:\n",
      "  accuracy: 0.7074829931972789\n",
      "  date: 2021-09-15_14-09-36\n",
      "  done: false\n",
      "  experiment_id: 211e3aa6d104480f813511e28f6bf05e\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 5\n",
      "  loss: 0.7810692344162915\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199265\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.1509833335876465\n",
      "  time_this_iter_s: 1.1316657066345215\n",
      "  time_total_s: 7.1509833335876465\n",
      "  timestamp: 1631707776\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 5\n",
      "  trial_id: c643d_00008\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [7,    10] loss: 0.939\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [7,    20] loss: 0.448\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [6,    10] loss: 0.799\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [7,    30] loss: 0.249\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [6,    20] loss: 0.345\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [6,    30] loss: 0.304\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [8,    10] loss: 0.798\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [8,    10] loss: 0.858\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [8,    20] loss: 0.411\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [8,    30] loss: 0.302\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [7,    10] loss: 0.740\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [7,    20] loss: 0.475\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [9,    10] loss: 0.764\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [7,    30] loss: 0.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [9,    10] loss: 0.929\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [9,    20] loss: 0.394\n",
      "== Status ==\n",
      "Memory usage on this node: 6.2/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 8.000: -0.8353999724259248 | Iter 4.000: -0.8294332156734141 | Iter 2.000: -1.0986120700836182 | Iter 1.000: -1.0986123085021973\n",
      "Resources requested: 3.0/12 CPUs, 0/0 GPUs, 0.0/6.26 GiB heap, 0.0/3.13 GiB objects\n",
      "Result logdir: /home/jhonerma/ML-Notebooks/CNN/Ray_Results/DEFAULT_2021-09-15_14-09-27\n",
      "Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n",
      "+---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "| Trial name          | status     | loc                |   l1 |   l2 |   l3 |          lr |   batch_size |     loss |   accuracy |   training_iteration |\n",
      "|---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------|\n",
      "| DEFAULT_c643d_00003 | RUNNING    | 10.67.95.37:199273 |  256 |  128 |   32 | 0.000380206 |            8 | 0.755953 |   0.727891 |                    9 |\n",
      "| DEFAULT_c643d_00008 | RUNNING    | 10.67.95.37:199265 |  128 |    8 |    8 | 0.00439477  |            4 | 0.780397 |   0.707483 |                    6 |\n",
      "| DEFAULT_c643d_00009 | RUNNING    | 10.67.95.37:199268 |    4 |   64 |   64 | 0.0772433   |            4 | 0.8354   |   0.687075 |                    8 |\n",
      "| DEFAULT_c643d_00000 | TERMINATED |                    |  128 |    8 |   32 | 0.00054301  |            4 | 1.09861  |   0.210884 |                    1 |\n",
      "| DEFAULT_c643d_00001 | TERMINATED |                    |   16 |    4 |  256 | 0.000347418 |            4 | 1.09861  |   0.22449  |                    1 |\n",
      "| DEFAULT_c643d_00002 | TERMINATED |                    |  256 |   32 |  512 | 0.00165889  |           32 | 1.09861  |   0.231293 |                    2 |\n",
      "| DEFAULT_c643d_00004 | TERMINATED |                    |   64 |  512 |    4 | 0.000179362 |           32 | 1.15751  |   0.238095 |                    1 |\n",
      "| DEFAULT_c643d_00005 | TERMINATED |                    |   64 |  512 |    4 | 0.00023156  |            8 | 1.09861  |   0.190476 |                    2 |\n",
      "| DEFAULT_c643d_00006 | TERMINATED |                    |    4 |   16 |   32 | 0.00704958  |           64 | 1.09861  |   0.22449  |                   10 |\n",
      "| DEFAULT_c643d_00007 | TERMINATED |                    |  512 |   32 |  128 | 0.0014271   |            4 | 1.09861  |   0.217687 |                    2 |\n",
      "+---------------------+------------+--------------------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [9,    30] loss: 0.274\n",
      "\u001b[2m\u001b[36m(pid=199273)\u001b[0m [10,    10] loss: 0.796\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [8,    10] loss: 0.829\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [10,    10] loss: 0.906\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [8,    20] loss: 0.434\n",
      "Result for DEFAULT_c643d_00003:\n",
      "  accuracy: 0.7278911564625851\n",
      "  date: 2021-09-15_14-09-39\n",
      "  done: true\n",
      "  experiment_id: d06bbe2892a44502a1dd0c9ae6948c90\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.7717789709568024\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199273\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.20369577407837\n",
      "  time_this_iter_s: 0.8682096004486084\n",
      "  time_total_s: 10.20369577407837\n",
      "  timestamp: 1631707779\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c643d_00003\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [10,    20] loss: 0.410\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [8,    30] loss: 0.214\n",
      "\u001b[2m\u001b[36m(pid=199268)\u001b[0m [10,    30] loss: 0.250\n",
      "Result for DEFAULT_c643d_00009:\n",
      "  accuracy: 0.6870748299319728\n",
      "  date: 2021-09-15_14-09-39\n",
      "  done: true\n",
      "  experiment_id: 83f948441e7c4824a8903a62db413e13\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.8386355195496533\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199268\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 10.485663890838623\n",
      "  time_this_iter_s: 0.8828535079956055\n",
      "  time_total_s: 10.485663890838623\n",
      "  timestamp: 1631707779\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c643d_00009\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [9,    10] loss: 0.757\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [9,    20] loss: 0.359\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [9,    30] loss: 0.305\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [10,    10] loss: 0.805\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [10,    20] loss: 0.381\n",
      "\u001b[2m\u001b[36m(pid=199265)\u001b[0m [10,    30] loss: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-15 14:09:41,791\tINFO tune.py:561 -- Total run time: 14.03 seconds (13.85 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DEFAULT_c643d_00008:\n",
      "  accuracy: 0.7074829931972789\n",
      "  date: 2021-09-15_14-09-41\n",
      "  done: true\n",
      "  experiment_id: 211e3aa6d104480f813511e28f6bf05e\n",
      "  hostname: jhonerma-tuxedo\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.7767397036423555\n",
      "  node_ip: 10.67.95.37\n",
      "  pid: 199265\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 12.626533031463623\n",
      "  time_this_iter_s: 1.0502207279205322\n",
      "  time_total_s: 12.626533031463623\n",
      "  timestamp: 1631707781\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: c643d_00008\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 5.7/15.1 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 8.000: -0.8081881017298311 | Iter 4.000: -0.8294332156734141 | Iter 2.000: -1.0986120700836182 | Iter 1.000: -1.0986123085021973\n",
      "Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/6.26 GiB heap, 0.0/3.13 GiB objects\n",
      "Result logdir: /home/jhonerma/ML-Notebooks/CNN/Ray_Results/DEFAULT_2021-09-15_14-09-27\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+---------------------+------------+-------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "| Trial name          | status     | loc   |   l1 |   l2 |   l3 |          lr |   batch_size |     loss |   accuracy |   training_iteration |\n",
      "|---------------------+------------+-------+------+------+------+-------------+--------------+----------+------------+----------------------|\n",
      "| DEFAULT_c643d_00000 | TERMINATED |       |  128 |    8 |   32 | 0.00054301  |            4 | 1.09861  |   0.210884 |                    1 |\n",
      "| DEFAULT_c643d_00001 | TERMINATED |       |   16 |    4 |  256 | 0.000347418 |            4 | 1.09861  |   0.22449  |                    1 |\n",
      "| DEFAULT_c643d_00002 | TERMINATED |       |  256 |   32 |  512 | 0.00165889  |           32 | 1.09861  |   0.231293 |                    2 |\n",
      "| DEFAULT_c643d_00003 | TERMINATED |       |  256 |  128 |   32 | 0.000380206 |            8 | 0.771779 |   0.727891 |                   10 |\n",
      "| DEFAULT_c643d_00004 | TERMINATED |       |   64 |  512 |    4 | 0.000179362 |           32 | 1.15751  |   0.238095 |                    1 |\n",
      "| DEFAULT_c643d_00005 | TERMINATED |       |   64 |  512 |    4 | 0.00023156  |            8 | 1.09861  |   0.190476 |                    2 |\n",
      "| DEFAULT_c643d_00006 | TERMINATED |       |    4 |   16 |   32 | 0.00704958  |           64 | 1.09861  |   0.22449  |                   10 |\n",
      "| DEFAULT_c643d_00007 | TERMINATED |       |  512 |   32 |  128 | 0.0014271   |            4 | 1.09861  |   0.217687 |                    2 |\n",
      "| DEFAULT_c643d_00008 | TERMINATED |       |  128 |    8 |    8 | 0.00439477  |            4 | 0.77674  |   0.707483 |                   10 |\n",
      "| DEFAULT_c643d_00009 | TERMINATED |       |    4 |   64 |   64 | 0.0772433   |            4 | 0.838636 |   0.687075 |                   10 |\n",
      "+---------------------+------------+-------+------+------+------+-------------+--------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Best trial config: {'l1': 256, 'l2': 128, 'l3': 32, 'lr': 0.00038020626505756613, 'batch_size': 8}\n",
      "Best trial final validation loss: 0.7717789709568024\n",
      "Best trial final validation accuracy: 0.7278911564625851\n",
      "/home/jhonerma/ML-Notebooks/CNN/Ray_Results/DEFAULT_2021-09-15_14-09-27/DEFAULT_c643d_00003_3_batch_size=8,l1=256,l2=128,l3=32,lr=0.00038021_2021-09-15_14-09-28/checkpoint_000009/checkpoint\n",
      "Best trial test set accuracy: 0.7021276595744681\n"
     ]
    }
   ],
   "source": [
    "main(num_samples=10, max_num_epochs=10, gpus_per_trial=gpus_per_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn-env]",
   "language": "python",
   "name": "conda-env-cnn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
