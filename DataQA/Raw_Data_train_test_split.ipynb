{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23b4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dc7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to data\n",
    "pi0_data_path = 'Data-Raw/pi0.npz'\n",
    "eta_data_path = 'Data-Raw/eta.npz'\n",
    "bck_data_path = 'Data-Raw/bck.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fbb30",
   "metadata": {},
   "source": [
    "Read in data and split the raw data into train and test sets\n",
    "This is done in a function, so that pythons garbage collect frees up any memory leaving scope of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67c7e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, test_size):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    \n",
    "    print(\"Start Loading Data\")\n",
    "    data_ClusterN = data[\"ClusterN\"]\n",
    "    data_Cluster = data[\"Cluster\"]\n",
    "    data_ClusterTiming = data[\"ClusterTiming\"]    \n",
    "    data_ClusterType = data[\"ClusterType\"]\n",
    "    data_ClusterE = data[\"ClusterE\"]\n",
    "    data_ClusterPt = data[\"ClusterPt\"]\n",
    "    data_ClusterModuleNumber = data[\"ClusterModuleNumber\"]\n",
    "    data_ClusterCol = data[\"ClusterCol\"]\n",
    "    data_ClusterRow = data[\"ClusterRow\"]\n",
    "    data_ClusterM02 = data[\"ClusterM02\"]\n",
    "    data_ClusterM20 = data[\"ClusterM20\"]\n",
    "    data_ClusterDistFromVert = data[\"ClusterDistFromVert\"]\n",
    "    data_PartE = data[\"PartE\"]\n",
    "    data_PartPt = data[\"PartPt\"]\n",
    "    data_PartEta = data[\"PartEta\"]\n",
    "    data_PartPhi = data[\"PartPhi\"]\n",
    "    if 'bck' in path:\n",
    "        data_PartIsPrimary = np.zeros_like(data_PartE, dtype=bool)\n",
    "    else:\n",
    "        data_PartIsPrimary = data[\"PartIsPrimary\"]\n",
    "    data_PartPID = data[\"PartPID\"]\n",
    "\n",
    "    \n",
    "    print(\"Start Splitting Data\")\n",
    "    data_ClusterN_train, data_ClusterN_test, data_Cluster_train, data_Cluster_test, data_ClusterTiming_train, \\\n",
    "    data_ClusterTiming_test, data_ClusterE_train, data_ClusterE_test, data_ClusterType_train,\\\n",
    "    data_ClusterType_test,data_ClusterPt_train, data_ClusterPt_test, data_ClusterModuleNumber_train,\\\n",
    "    data_ClusterModuleNumber_test, data_ClusterCol_train, data_ClusterCol_test, data_ClusterRow_train,\\\n",
    "    data_ClusterRow_test, data_ClusterM02_train, data_ClusterM02_test, data_ClusterM20_train,\\\n",
    "    data_ClusterM20_test, data_ClusterDistFromVert_train, data_ClusterDistFromVert_test, data_PartE_train,\\\n",
    "    data_PartE_test, data_PartPt_train, data_PartPt_test, data_PartEta_train, data_PartEta_test,\\\n",
    "    data_PartPhi_train, data_PartPhi_test, data_PartIsPrimary_train, data_PartIsPrimary_test,\\\n",
    "    data_PartPID_train, data_PartPID_test = train_test_split(\n",
    "        data_ClusterN, data_Cluster, data_ClusterTiming, data_ClusterE, data_ClusterType, data_ClusterPt,\n",
    "        data_ClusterModuleNumber, data_ClusterCol, data_ClusterRow, data_ClusterM02, data_ClusterM20,\n",
    "        data_ClusterDistFromVert, data_PartE, data_PartPt, data_PartEta, data_PartPhi, data_PartIsPrimary, \n",
    "        data_PartPID, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return (data_ClusterN_train, data_ClusterN_test, data_Cluster_train, data_Cluster_test\n",
    "        , data_ClusterTiming_train, data_ClusterTiming_test, data_ClusterE_train, data_ClusterE_test\n",
    "        , data_ClusterType_train, data_ClusterType_test, data_ClusterPt_train, data_ClusterPt_test\n",
    "        , data_ClusterModuleNumber_train, data_ClusterModuleNumber_test, data_ClusterCol_train\n",
    "        , data_ClusterCol_test, data_ClusterRow_train, data_ClusterRow_test, data_ClusterM02_train\n",
    "        , data_ClusterM02_test, data_ClusterM20_train, data_ClusterM20_test, data_ClusterDistFromVert_train\n",
    "        , data_ClusterDistFromVert_test, data_PartE_train, data_PartE_test, data_PartPt_train, data_PartPt_test\n",
    "        , data_PartEta_train, data_PartEta_test, data_PartPhi_train, data_PartPhi_test\n",
    "        , data_PartIsPrimary_train, data_PartIsPrimary_test, data_PartPID_train, data_PartPID_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f327ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(path, name,test_size=0.2):\n",
    "    \n",
    "    print(\"------- Start Splitting {} Data -------\".format(name))\n",
    "    data = load_data(path, test_size) \n",
    "    \n",
    "    #Keywords in data for train/test\n",
    "    #0 ClusterN, 2 Cluster, 4 ClusterTiming, 6 ClusterE, 8 ClusterType, 10 ClusterPt, 12 ClusterModuleNumber\n",
    "    #, 14 ClusterCol, 16 ClusterRow, 18 ClusterM02, 20 ClusterM20, 22 ClusterDistFromVert, 24 PartE, 26 PartPt\n",
    "    #, 28 PartEta, 30 PartPhi, 32 PartIsPrimary, 34 PartPID\n",
    "    #test in data has index+1\n",
    "\n",
    "    print(\"Saving {} Train Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_train', Size=data[0].size\n",
    "                        , ClusterN=data[0], Cluster=data[2]\n",
    "                        , ClusterTiming=data[4], ClusterE=data[6]\n",
    "                        , ClusterPt=data[10], ClusterModuleNumber=data[12]\n",
    "                        , ClusterType=data[8], ClusterRow=data[16]\n",
    "                        , ClusterCol=data[14], ClusterM02=data[18]\n",
    "                        , ClusterM20=data[20], ClusterDistFromVert=data[22] \n",
    "                        , PartE=data[24], PartPt=data[26], PartEta=data[28]\n",
    "                        , PartPhi=data[30], PartIsPrimary=data[32]\n",
    "                        , PartPID=data[34])\n",
    "\n",
    "    print(\"Saving {} Test Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_test', Size=data[1].size, ClusterN=data[1]\n",
    "                        , Cluster=data[3], ClusterTiming=data[5]\n",
    "                        , ClusterE=data[7], ClusterPt=data[11]\n",
    "                        , ClusterModuleNumber=data[13], ClusterType=data[9]\n",
    "                        , ClusterRow=data[17], ClusterCol=data[15]\n",
    "                        , ClusterM02=data[19], ClusterM20=data[21]\n",
    "                        , ClusterDistFromVert=data[23], PartE=data[25]\n",
    "                        , PartPt=data[27], PartEta=data[29], PartPhi=data[31]\n",
    "                        , PartIsPrimary=data[33], PartPID=data[35])\n",
    "    \n",
    "    print(\"----- Finished Splitting {} Data ------\\n\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887bda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting pi0 Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving pi0 Train Data\n",
      "Saving pi0 Test Data\n",
      "----- Finished Splitting pi0 Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(pi0_data_path, 'pi0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bde745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting eta Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving eta Train Data\n",
      "Saving eta Test Data\n",
      "----- Finished Splitting eta Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(eta_data_path, 'eta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07246dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting bck Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving bck Train Data\n",
      "Saving bck Test Data\n",
      "----- Finished Splitting bck Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(bck_data_path, 'bck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5655c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root-env]",
   "language": "python",
   "name": "conda-env-root-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
