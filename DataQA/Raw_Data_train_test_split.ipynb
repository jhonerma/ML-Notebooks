{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23b4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import path\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dc7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to data\n",
    "pi0_data_path = path.abspath('Data-Raw/pi0.npz')\n",
    "eta_data_path = path.abspath('Data-Raw/eta.npz')\n",
    "bck_data_path = path.abspath('Data-Raw/bck.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fbb30",
   "metadata": {},
   "source": [
    "Read in data and split the raw data into train and test sets\n",
    "This is done in a function, so that pythons garbage collect frees up any memory leaving scope of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1325069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, test_size):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    \n",
    "    print(\"Start Loading Data\")\n",
    "    data_ClusterCellN = data[\"ClusterCellN\"]\n",
    "    data_CellEnergy = data[\"CellEnergy\"]\n",
    "    data_CellTiming = data[\"CellTiming\"]   \n",
    "    data_CellModuleNumber = data[\"CellModuleNumber\"]\n",
    "    data_CellCol = data[\"CellCol\"]\n",
    "    data_CellRow = data[\"CellRow\"]\n",
    "    data_ClusterType = data[\"ClusterType\"]\n",
    "    data_ClusterE = data[\"ClusterE\"]\n",
    "    data_ClusterPt = data[\"ClusterPt\"]\n",
    "    data_ClusterM02 = data[\"ClusterM02\"]\n",
    "    data_ClusterM20 = data[\"ClusterM20\"]\n",
    "    data_ClusterDistFromVert = data[\"ClusterDistFromVert\"]\n",
    "    data_PartE = data[\"PartE\"]\n",
    "    data_PartPt = data[\"PartPt\"]\n",
    "    data_PartEta = data[\"PartEta\"]\n",
    "    data_PartPhi = data[\"PartPhi\"]\n",
    "    if 'bck' in path:\n",
    "        data_PartIsPrimary = np.zeros_like(data_PartE, dtype=bool)\n",
    "    else:\n",
    "        data_PartIsPrimary = data[\"PartIsPrimary\"]\n",
    "    data_PartPID = data[\"PartPID\"]\n",
    "\n",
    "    \n",
    "    print(\"Start Splitting Data\")\n",
    "    \n",
    "    #Keywords in train_test_data\n",
    "    #train arryas have even index listed below\n",
    "    #0 ClusterCellN, 2 CellEnergy, 4 CellTiming, 6 CellModuleNumber, 8 CellCol, 10 CellRow,\n",
    "    #12 ClusterE, 14 ClusterType, 16 ClusterPt, 18 ClusterM02, 20 ClusterM20, 22 ClusterDistFromVert, \n",
    "    #24 PartE, 26 PartPt, 28 PartEta, 30 PartPhi, 32 PartIsPrimary, 34 PartPID\n",
    "    #test in data has index+1\n",
    "    train_test_data = train_test_split(\n",
    "        data_ClusterCellN, data_CellEnergy, data_CellTiming, data_CellModuleNumber, data_CellCol, data_CellRow, \n",
    "        data_ClusterE, data_ClusterType, data_ClusterPt, data_ClusterM02, data_ClusterM20,\n",
    "        data_ClusterDistFromVert, data_PartE, data_PartPt, data_PartEta, data_PartPhi, data_PartIsPrimary, \n",
    "        data_PartPID, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5588a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(path, name, test_size=0.2):\n",
    "    \n",
    "    print(\"------- Start Splitting {} Data -------\".format(name))\n",
    "    data = load_data(path, test_size) \n",
    "    \n",
    "    #Keywords in data for train/test\n",
    "    #train arryas have even index listed below\n",
    "    #0 ClusterCellN, 2 CellEnergy, 4 CellTiming, 6 CellModuleNumber, 8 CellCol, 10 CellRow,\n",
    "    #12 ClusterE, 14 ClusterType, 16 ClusterPt, 18 ClusterM02, 20 ClusterM20, 22 ClusterDistFromVert, \n",
    "    #24 PartE, 26 PartPt, 28 PartEta, 30 PartPhi, 32 PartIsPrimary, 34 PartPID\n",
    "    #test in data has index+1\n",
    "\n",
    "    print(\"Saving {} Train Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_train', Size=data[0].size\n",
    "                        , ClusterCellN=data[0], CellEnergy=data[2]\n",
    "                        , CellTiming=data[4], CellModuleNumber=data[6]\n",
    "                        , CellCol=data[8], CellRow=data[10]\n",
    "                        , ClusterE=data[12], ClusterPt=data[16]\n",
    "                        , ClusterType=data[14], ClusterM02=data[18]\n",
    "                        , ClusterM20=data[20], ClusterDistFromVert=data[22] \n",
    "                        , PartE=data[24], PartPt=data[26], PartEta=data[28]\n",
    "                        , PartPhi=data[30], PartIsPrimary=data[32]\n",
    "                        , PartPID=data[34])\n",
    "\n",
    "    print(\"Saving {} Test Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_test', Size=data[1].size, ClusterN=data[1]\n",
    "                        , CellEnergy=data[3], CellTiming=data[5]\n",
    "                        , CellModuleNumber=data[7] , CellCol=data[9]\n",
    "                        , CellRow=data[11], ClusterE=data[13], ClusterPt=data[17]\n",
    "                        , ClusterType=data[15], ClusterM02=data[19]\n",
    "                        , ClusterM20=data[21], ClusterDistFromVert=data[23], PartE=data[25]\n",
    "                        , PartPt=data[27], PartEta=data[29], PartPhi=data[31]\n",
    "                        , PartIsPrimary=data[33], PartPID=data[35])\n",
    "    \n",
    "    print(\"----- Finished Splitting {} Data ------\\n\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887bda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting pi0 Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving pi0 Train Data\n",
      "Saving pi0 Test Data\n",
      "----- Finished Splitting pi0 Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(pi0_data_path, 'pi0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bde745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting eta Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving eta Train Data\n",
      "Saving eta Test Data\n",
      "----- Finished Splitting eta Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(eta_data_path, 'eta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07246dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting bck Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving bck Train Data\n",
      "Saving bck Test Data\n",
      "----- Finished Splitting bck Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(bck_data_path, 'bck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c5c029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root-env]",
   "language": "python",
   "name": "conda-env-root-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
