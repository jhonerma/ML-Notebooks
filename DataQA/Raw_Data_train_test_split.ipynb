{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23b4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dc7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to data\n",
    "pi0_data_path = 'Data-Raw/pi0.npz'\n",
    "eta_data_path = 'Data-Raw/eta.npz'\n",
    "bck_data_path = 'Data-Raw/bck.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632fbb30",
   "metadata": {},
   "source": [
    "Read in data and split the raw data into train and test sets\n",
    "This is done in a function, so that pythons garbage collect frees up any memory leaving scope of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c7e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, test_size):\n",
    "    data = np.load(path, allow_pickle=True)\n",
    "    \n",
    "    print(\"Start Loading Data\")\n",
    "    data_ClusterN = data[\"ClusterN\"]\n",
    "    data_Cluster = data[\"Cluster\"]\n",
    "    data_ClusterTiming = data[\"ClusterTiming\"]    \n",
    "    data_ClusterType = data[\"ClusterType\"]\n",
    "    data_ClusterE = data[\"ClusterE\"]\n",
    "    data_ClusterPt = data[\"ClusterPt\"]\n",
    "    data_ClusterModuleNumber = data[\"ClusterModuleNumber\"]\n",
    "    data_ClusterCol = data[\"ClusterCol\"]\n",
    "    data_ClusterRow = data[\"ClusterRow\"]\n",
    "    data_ClusterM02 = data[\"ClusterM02\"]\n",
    "    data_ClusterM20 = data[\"ClusterM20\"]\n",
    "    data_ClusterDistFromVert = data[\"ClusterDistFromVert\"]\n",
    "    data_PartE = data[\"PartE\"]\n",
    "    data_PartPt = data[\"PartPt\"]\n",
    "    data_PartEta = data[\"PartEta\"]\n",
    "    data_PartPhi = data[\"PartPhi\"]\n",
    "    if 'bck' in path:\n",
    "        data_PartIsPrimary = np.zeros_like(data_PartE, dtype=bool)\n",
    "    else:\n",
    "        data_PartIsPrimary = data[\"PartIsPrimary\"]\n",
    "    data_PartPID = data[\"PartPID\"]\n",
    "\n",
    "    \n",
    "    print(\"Start Splitting Data\")\n",
    "    data_ClusterN_train, data_ClusterN_test, data_Cluster_train, data_Cluster_test, data_ClusterTiming_train, \\\n",
    "    data_ClusterTiming_test, data_ClusterE_train, data_ClusterE_test, data_ClusterType_train,\\\n",
    "    data_ClusterType_test,data_ClusterPt_train, data_ClusterPt_test, data_ClusterModuleNumber_train,\\\n",
    "    data_ClusterModuleNumber_test, data_ClusterCol_train, data_ClusterCol_test, data_ClusterRow_train,\\\n",
    "    data_ClusterRow_test, data_ClusterM02_train, data_ClusterM02_test, data_ClusterM20_train,\\\n",
    "    data_ClusterM20_test, data_ClusterDistFromVert_train, data_ClusterDistFromVert_test, data_PartE_train,\\\n",
    "    data_PartE_test, data_PartPt_train, data_PartPt_test, data_PartEta_train, data_PartEta_test,\\\n",
    "    data_PartPhi_train, data_PartPhi_test, data_PartIsPrimary_train, data_PartIsPrimary_test,\\\n",
    "    data_PartPID_train, data_PartPID_test = train_test_split(\n",
    "        data_ClusterN, data_Cluster, data_ClusterTiming, data_ClusterE, data_ClusterType, data_ClusterPt,\n",
    "        data_ClusterModuleNumber, data_ClusterCol, data_ClusterRow, data_ClusterM02, data_ClusterM20,\n",
    "        data_ClusterDistFromVert, data_PartE, data_PartPt, data_PartEta, data_PartPhi, data_PartIsPrimary, \n",
    "        data_PartPID, test_size=test_size, random_state=42)\n",
    "    \n",
    "    return (data_ClusterN_train, data_ClusterN_test, data_Cluster_train, data_Cluster_test\n",
    "        , data_ClusterTiming_train, data_ClusterTiming_test, data_ClusterE_train, data_ClusterE_test\n",
    "        , data_ClusterType_train, data_ClusterType_test, data_ClusterPt_train, data_ClusterPt_test\n",
    "        , data_ClusterModuleNumber_train, data_ClusterModuleNumber_test, data_ClusterCol_train\n",
    "        , data_ClusterCol_test, data_ClusterRow_train, data_ClusterRow_test, data_ClusterM02_train\n",
    "        , data_ClusterM02_test, data_ClusterM20_train, data_ClusterM20_test, data_ClusterDistFromVert_train\n",
    "        , data_ClusterDistFromVert_test, data_PartE_train, data_PartE_test, data_PartPt_train, data_PartPt_test\n",
    "        , data_PartEta_train, data_PartEta_test, data_PartPhi_train, data_PartPhi_test\n",
    "        , data_PartIsPrimary_train, data_PartIsPrimary_test, data_PartPID_train, data_PartPID_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9e9b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(path, name,test_size=0.2):\n",
    "    \n",
    "    print(\"------- Start Splitting {} Data -------\".format(name))\n",
    "    data_ClusterN_train, data_ClusterN_test, data_Cluster_train, data_Cluster_test, data_ClusterTiming_train,\\\n",
    "    data_ClusterTiming_test, data_ClusterE_train, data_ClusterE_test, data_ClusterType_train,\\\n",
    "    data_ClusterType_test,data_ClusterPt_train, data_ClusterPt_test, data_ClusterModuleNumber_train,\\\n",
    "    data_ClusterModuleNumber_test, data_ClusterCol_train, data_ClusterCol_test, data_ClusterRow_train,\\\n",
    "    data_ClusterRow_test, data_ClusterM02_train, data_ClusterM02_test, data_ClusterM20_train,\\\n",
    "    data_ClusterM20_test, data_ClusterDistFromVert_train, data_ClusterDistFromVert_test, data_PartE_train,\\\n",
    "    data_PartE_test, data_PartPt_train, data_PartPt_test, data_PartEta_train, data_PartEta_test,\\\n",
    "    data_PartPhi_train, data_PartPhi_test, data_PartIsPrimary_train, data_PartIsPrimary_test,\\\n",
    "    data_PartPID_train, data_PartPID_test = load_data(path, test_size) \n",
    "    \n",
    "    print(\"Saving {} Train Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_train', Size=data_ClusterE_train.size\n",
    "                        , ClusterN=data_ClusterN_train, Cluster=data_Cluster_train\n",
    "                        , ClusterTiming=data_ClusterTiming_train, ClusterE=data_ClusterE_train\n",
    "                        , ClusterPt=data_ClusterPt_train, ClusterModuleNumber=data_ClusterModuleNumber_train\n",
    "                        , ClusterType=data_ClusterType_train, ClusterRow=data_ClusterRow_train\n",
    "                        , ClusterCol=data_ClusterCol_train, ClusterM02=data_ClusterM02_train\n",
    "                        , ClusterM20=data_ClusterM20_train, ClusterDistFromVert=data_ClusterDistFromVert_train \n",
    "                        , PartE=data_PartE_train, PartPt=data_PartPt_train, PartEta=data_PartEta_train\n",
    "                        , PartPhi=data_PartPhi_train, PartIsPrimary=data_PartIsPrimary_train\n",
    "                        , PartPID=data_PartPID_train)\n",
    "\n",
    "    print(\"Saving {} Test Data\".format(name))\n",
    "    np.savez_compressed('Data-Split/'+name+'_test', Size=data_ClusterE_test.size, ClusterN=data_ClusterN_test\n",
    "                        , Cluster=data_Cluster_test, ClusterTiming=data_ClusterTiming_test\n",
    "                        , ClusterE=data_ClusterE_test, ClusterPt=data_ClusterPt_test\n",
    "                        , ClusterModuleNumber=data_ClusterModuleNumber_test, ClusterType=data_ClusterType_test\n",
    "                        , ClusterRow=data_ClusterRow_test, ClusterCol=data_ClusterCol_test\n",
    "                        , ClusterM02=data_ClusterM02_test, ClusterM20=data_ClusterM20_test\n",
    "                        , ClusterDistFromVert=data_ClusterDistFromVert_test, PartE=data_PartE_test\n",
    "                        , PartPt=data_PartPt_test, PartEta=data_PartEta_test, PartPhi=data_PartPhi_test\n",
    "                        , PartIsPrimary=data_PartIsPrimary_test, PartPID=data_PartPID_test)\n",
    "    \n",
    "    print(\"----- Finished Splitting {} Data ------\\n\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887bda80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting pi0 Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving pi0 Train Data\n",
      "Saving pi0 Test Data\n",
      "----- Finished Splitting pi0 Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(pi0_data_path, 'pi0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bde745b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting eta Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving eta Train Data\n",
      "Saving eta Test Data\n",
      "----- Finished Splitting eta Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(eta_data_path, 'eta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07246dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Start Splitting bck Data -------\n",
      "Start Loading Data\n",
      "Start Splitting Data\n",
      "Saving bck Train Data\n",
      "Saving bck Test Data\n",
      "----- Finished Splitting bck Data ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(bck_data_path, 'bck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32209a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root-env]",
   "language": "python",
   "name": "conda-env-root-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
